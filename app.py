# app.py
# -*- coding: utf-8 -*-
import os
import re
import json
from datetime import datetime
from typing import Dict, List, Tuple, Optional

import requests
from flask import Flask, render_template, request, jsonify, Response
from dotenv import load_dotenv

from docx import Document
from pypdf import PdfReader

from openpyxl import load_workbook
import xlrd

from pptx import Presentation


load_dotenv()

APP_TITLE = "Chuã£ã¨ğŸ‘„RAGãƒŠãƒ¬ãƒƒã‚¸å¤‰æ›ï¼ˆMarkdownï¼‰"
HEADER_MODEL_LABEL = "Model : ChatGPT 5.2"

API_BASE = (os.getenv("DIFY_API_BASE") or "").strip().rstrip("/")
API_KEY = (os.getenv("DIFY_API_KEY") or "").strip()

ALLOWED_EXTS = {
    ".txt", ".md", ".csv", ".json", ".log",
    ".html", ".xml", ".yml", ".yaml", ".ini", ".conf",
    ".py", ".js", ".css",
    ".docx", ".pdf",
    ".xlsx", ".xls", ".xlsm",
    ".ppt", ".pptx",
}

MAX_INPUT_CHARS = 180_000
DEFAULT_CHUNK_SEP = "***"
REQ_TIMEOUT_SEC = 300


def create_app():
    app = Flask(__name__)
    app.config["JSON_AS_ASCII"] = False

    @app.get("/")
    def index():
        return render_template(
            "index.html",
            title=APP_TITLE,
            model_label=HEADER_MODEL_LABEL,
            api_ready=bool(API_BASE and API_KEY),
        )

    @app.get("/api/health")
    def api_health():
        return jsonify({
            "ok": True,
            "api_ready": bool(API_BASE and API_KEY),
            "model_label": HEADER_MODEL_LABEL,
        })

    @app.post("/api/scan")
    def api_scan():
        data = request.get_json(force=True) or {}
        in_dir = (data.get("input_dir") or "").strip()
        recursive = bool(data.get("recursive", True))

        if not in_dir or not os.path.isdir(in_dir):
            return jsonify({"ok": False, "error": "å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"}), 400

        files = list_files(in_dir, recursive=recursive)
        return jsonify({"ok": True, "count": len(files), "files": files})

    @app.post("/api/run")
    def api_run():
        if not API_BASE or not API_KEY:
            return jsonify({
                "ok": False,
                "error": "ã‚µãƒ¼ãƒãƒ¼å´APIè¨­å®šãŒæœªå®Œäº†ã§ã™ã€‚.env ã« DIFY_API_BASE / DIFY_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
            }), 500

        data = request.get_json(force=True) or {}

        input_dir = (data.get("input_dir") or "").strip()
        output_dir = (data.get("output_dir") or "").strip()
        recursive = bool(data.get("recursive", True))

        user = (data.get("user") or "rag_converter").strip()
        knowledge_style = (data.get("knowledge_style") or "rag_markdown").strip()
        chunk_sep = (data.get("chunk_sep") or DEFAULT_CHUNK_SEP).strip() or DEFAULT_CHUNK_SEP

        overwrite = bool(data.get("overwrite", False))

        if not input_dir or not os.path.isdir(input_dir):
            return jsonify({"ok": False, "error": "å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"}), 400
        if not output_dir:
            return jsonify({"ok": False, "error": "å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒæœªæŒ‡å®šã§ã™ã€‚"}), 400

        os.makedirs(output_dir, exist_ok=True)
        files = list_files(input_dir, recursive=recursive)

        def sse():
            yield sse_event("meta", {
                "title": APP_TITLE,
                "model": HEADER_MODEL_LABEL,
                "total": len(files),
                "overwrite": overwrite,
            })

            ok_count = 0
            ng_count = 0
            skip_count = 0

            for idx, relpath in enumerate(files, start=1):
                abspath = os.path.join(input_dir, relpath)
                yield sse_event("progress", {"index": idx, "total": len(files), "file": relpath})

                try:
                    out_path = make_output_path(output_dir, relpath)

                    if (not overwrite) and os.path.exists(out_path):
                        skip_count += 1
                        yield sse_event("skip_one", {"file": relpath, "out": os.path.relpath(out_path, output_dir)})
                        continue

                    raw_text, meta = extract_text(abspath, knowledge_style=knowledge_style)

                    if not raw_text.strip():
                        raise RuntimeError("æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã—ãŸã€‚")

                    if len(raw_text) > MAX_INPUT_CHARS:
                        raw_text = raw_text[:MAX_INPUT_CHARS] + "\n...(truncated)\n"

                    md = convert_via_dify_chat_messages_secure(
                        api_base=API_BASE,
                        api_key=API_KEY,
                        user=user,
                        source_path=relpath,
                        source_meta=meta,
                        text=raw_text,
                        knowledge_style=knowledge_style,
                        chunk_sep=chunk_sep,
                    )

                    os.makedirs(os.path.dirname(out_path), exist_ok=True)
                    with open(out_path, "w", encoding="utf-8", newline="\n") as f:
                        f.write(md)

                    ok_count += 1
                    yield sse_event("done_one", {"file": relpath, "out": os.path.relpath(out_path, output_dir)})

                except Exception as e:
                    ng_count += 1
                    yield sse_event("error_one", {"file": relpath, "error": safe_err(str(e))})

            yield sse_event("summary", {
                "ok": ok_count,
                "ng": ng_count,
                "skip": skip_count,
                "total": len(files),
                "overwrite": overwrite,
            })

        return Response(sse(), mimetype="text/event-stream")

    return app


def list_files(root_dir: str, recursive: bool = True) -> List[str]:
    results: List[str] = []
    root_dir = os.path.abspath(root_dir)

    if recursive:
        for base, _, files in os.walk(root_dir):
            for name in files:
                ext = os.path.splitext(name)[1].lower()
                if ext in ALLOWED_EXTS:
                    abs_path = os.path.join(base, name)
                    rel = os.path.relpath(abs_path, root_dir)
                    results.append(rel)
    else:
        for name in os.listdir(root_dir):
            abs_path = os.path.join(root_dir, name)
            if os.path.isfile(abs_path):
                ext = os.path.splitext(name)[1].lower()
                if ext in ALLOWED_EXTS:
                    results.append(name)

    results.sort()
    return results


def extract_text(path: str, knowledge_style: str = "rag_markdown") -> Tuple[str, Dict[str, str]]:
    ext = os.path.splitext(path)[1].lower()
    stat = os.stat(path)
    meta = {
        "filename": os.path.basename(path),
        "ext": ext,
        "size_bytes": str(stat.st_size),
        "mtime": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S"),
    }

    if ext in {
        ".txt", ".md", ".csv", ".json", ".log",
        ".html", ".xml", ".yml", ".yaml", ".ini", ".conf",
        ".py", ".js", ".css",
    }:
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            return f.read(), meta

    if ext == ".docx":
        doc = Document(path)
        parts = []
        for p in doc.paragraphs:
            t = p.text.strip()
            if t:
                parts.append(t)
        return "\n".join(parts), meta

    if ext == ".pdf":
        return extract_pdf_like(path), meta

    if ext in {".xlsx", ".xlsm", ".xls"}:
        if knowledge_style == "rag_natural":
            text = extract_excel_as_markdown_tables(path, ext)
        else:
            text = extract_excel_as_row_records(path, ext)
        return text, meta

    if ext in {".ppt", ".pptx"}:
        return extract_ppt_like(path, ext), meta

    raise RuntimeError(f"æœªå¯¾å¿œã®æ‹¡å¼µå­ã§ã™: {ext}")


def extract_pdf_like(path: str) -> str:
    reader = PdfReader(path)
    parts = []
    for i, page in enumerate(reader.pages):
        txt = page.extract_text() or ""
        txt = normalize_pdf_like_text(txt)
        if txt.strip():
            parts.append(f"[PAGE {i+1}]\n{txt}")
    return "\n\n".join(parts)


def extract_excel_as_row_records(path: str, ext: str) -> str:
    if ext == ".xls":
        return extract_xls_as_row_records(path)
    return extract_xlsx_like_as_row_records(path)


def extract_xlsx_like_as_row_records(path: str) -> str:
    wb = load_workbook(path, data_only=True, read_only=True)
    out: List[str] = []

    for sheet in wb.worksheets:
        out.append(f"[SHEET: {sheet.title}]")

        rows = list(sheet.iter_rows(values_only=True))
        if not rows:
            out.append("[EMPTY]")
            out.append("")
            continue

        header: Optional[List[str]] = None
        start_idx = 0
        for i, r in enumerate(rows):
            if any(cell is not None and str(cell).strip() != "" for cell in r):
                header = [sanitize_header(cell) for cell in r]
                start_idx = i + 1
                break

        if not header:
            out.append("[EMPTY]")
            out.append("")
            continue

        out.append("[HEADER] " + "\t".join([h if h else "" for h in header]))

        for ridx in range(start_idx, len(rows)):
            r = rows[ridx]
            if not any(cell is not None and str(cell).strip() != "" for cell in r):
                continue

            record = {}
            for cidx, cell in enumerate(r):
                key = header[cidx] if cidx < len(header) else f"COL{cidx+1}"
                if not key:
                    key = f"COL{cidx+1}"
                val = "" if cell is None else str(cell).strip()
                if val != "":
                    record[key] = val

            if record:
                out.append("[ROW] " + json.dumps(record, ensure_ascii=False, separators=(",", ":")))

        out.append("")

    return "\n".join(out).strip()


def extract_xls_as_row_records(path: str) -> str:
    wb = xlrd.open_workbook(path)
    out: List[str] = []

    for sheet in wb.sheets():
        out.append(f"[SHEET: {sheet.name}]")

        if sheet.nrows <= 0:
            out.append("[EMPTY]")
            out.append("")
            continue

        rows = []
        for r in range(sheet.nrows):
            rows.append([sheet.cell_value(r, c) for c in range(sheet.ncols)])

        header: Optional[List[str]] = None
        start_idx = 0
        for i, r in enumerate(rows):
            if any(cell is not None and str(cell).strip() != "" for cell in r):
                header = [sanitize_header(cell) for cell in r]
                start_idx = i + 1
                break

        if not header:
            out.append("[EMPTY]")
            out.append("")
            continue

        out.append("[HEADER] " + "\t".join([h if h else "" for h in header]))

        for ridx in range(start_idx, len(rows)):
            r = rows[ridx]
            if not any(cell is not None and str(cell).strip() != "" for cell in r):
                continue

            record = {}
            for cidx, cell in enumerate(r):
                key = header[cidx] if cidx < len(header) else f"COL{cidx+1}"
                if not key:
                    key = f"COL{cidx+1}"
                val = "" if cell is None else str(cell).strip()
                if val != "":
                    record[key] = val

            if record:
                out.append("[ROW] " + json.dumps(record, ensure_ascii=False, separators=(",", ":")))

        out.append("")

    return "\n".join(out).strip()


def extract_excel_as_markdown_tables(path: str, ext: str) -> str:
    if ext == ".xls":
        return extract_xls_as_markdown_tables(path)
    return extract_xlsx_like_as_markdown_tables(path)


def extract_xlsx_like_as_markdown_tables(path: str) -> str:
    MAX_ROWS_PER_SHEET = 200
    wb = load_workbook(path, data_only=True, read_only=True)

    out: List[str] = []
    for sheet in wb.worksheets:
        out.append(f"[SHEET: {sheet.title}]")

        rows = list(sheet.iter_rows(values_only=True))
        if not rows:
            out.append("(empty)")
            out.append("")
            continue

        header = None
        start_idx = 0
        for i, r in enumerate(rows):
            if any(cell is not None and str(cell).strip() != "" for cell in r):
                header = [sanitize_header(c) for c in r]
                start_idx = i + 1
                break
        if not header:
            out.append("(empty)")
            out.append("")
            continue

        cols = [h if h else f"COL{j+1}" for j, h in enumerate(header)]

        out.append("| " + " | ".join(cols) + " |")
        out.append("| " + " | ".join(["---"] * len(cols)) + " |")

        count = 0
        for ridx in range(start_idx, len(rows)):
            r = rows[ridx]
            if not any(cell is not None and str(cell).strip() != "" for cell in r):
                continue

            vals = []
            for cidx in range(len(cols)):
                cell = r[cidx] if cidx < len(r) else None
                v = "" if cell is None else str(cell).strip()
                v = v.replace("\n", " ").replace("\r", " ")
                v = v.replace("|", "\\|")
                vals.append(v)

            out.append("| " + " | ".join(vals) + " |")
            count += 1
            if count >= MAX_ROWS_PER_SHEET:
                out.append(f"(â€¦ {MAX_ROWS_PER_SHEET}è¡Œã¾ã§è¡¨ç¤ºã€‚ç¶šãã¯çœç•¥ â€¦)")
                break

        out.append("")

    return "\n".join(out).strip()


def extract_xls_as_markdown_tables(path: str) -> str:
    MAX_ROWS_PER_SHEET = 200
    wb = xlrd.open_workbook(path)
    out: List[str] = []

    for sheet in wb.sheets():
        out.append(f"[SHEET: {sheet.name}]")

        if sheet.nrows <= 0:
            out.append("(empty)")
            out.append("")
            continue

        rows = []
        for r in range(sheet.nrows):
            rows.append([sheet.cell_value(r, c) for c in range(sheet.ncols)])

        header = None
        start_idx = 0
        for i, r in enumerate(rows):
            if any(cell is not None and str(cell).strip() != "" for cell in r):
                header = [sanitize_header(c) for c in r]
                start_idx = i + 1
                break
        if not header:
            out.append("(empty)")
            out.append("")
            continue

        cols = [h if h else f"COL{j+1}" for j, h in enumerate(header)]

        out.append("| " + " | ".join(cols) + " |")
        out.append("| " + " | ".join(["---"] * len(cols)) + " |")

        count = 0
        for ridx in range(start_idx, len(rows)):
            r = rows[ridx]
            if not any(cell is not None and str(cell).strip() != "" for cell in r):
                continue

            vals = []
            for cidx in range(len(cols)):
                cell = r[cidx] if cidx < len(r) else None
                v = "" if cell is None else str(cell).strip()
                v = v.replace("\n", " ").replace("\r", " ")
                v = v.replace("|", "\\|")
                vals.append(v)

            out.append("| " + " | ".join(vals) + " |")
            count += 1
            if count >= MAX_ROWS_PER_SHEET:
                out.append(f"(â€¦ {MAX_ROWS_PER_SHEET}è¡Œã¾ã§è¡¨ç¤ºã€‚ç¶šãã¯çœç•¥ â€¦)")
                break

        out.append("")

    return "\n".join(out).strip()


def extract_ppt_like(path: str, ext: str) -> str:
    try:
        prs = Presentation(path)
    except Exception:
        if ext == ".ppt":
            raise RuntimeError("`.ppt`ï¼ˆæ—§å½¢å¼ï¼‰ã¯ python-pptx ã§ç›´æ¥èª­ã‚ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚`.pptx` ã«å¤‰æ›ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        raise RuntimeError("PowerPointã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ç ´æã¾ãŸã¯å½¢å¼ãŒæƒ³å®šå¤–ã§ã™ã€‚")

    parts: List[str] = []
    for i, slide in enumerate(prs.slides):
        slide_text: List[str] = []
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                t = (shape.text or "").strip()
                if t:
                    slide_text.append(t)

        txt = "\n".join(slide_text)
        txt = normalize_pdf_like_text(txt)
        if txt.strip():
            parts.append(f"[SLIDE {i+1}]\n{txt}")

    return "\n\n".join(parts)


def sanitize_header(cell) -> str:
    if cell is None:
        return ""
    s = str(cell).strip()
    s = re.sub(r"\s+", " ", s)
    return s


def normalize_pdf_like_text(s: str) -> str:
    lines = [ln.rstrip() for ln in s.splitlines()]
    out: List[str] = []
    buf = ""

    def flush():
        nonlocal buf
        if buf:
            out.append(buf)
            buf = ""

    for ln in lines:
        t = ln.strip("\u00a0 ").strip()
        if not t:
            flush()
            out.append("")
            continue
        if len(t) == 1:
            buf += t
        else:
            flush()
            out.append(t)
    flush()

    text = "\n".join(out)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()


def make_output_path(output_dir: str, rel_input_path: str) -> str:
    base, _ = os.path.splitext(rel_input_path)
    safe = sanitize_relpath(base) + ".md"
    return os.path.join(output_dir, safe)


def sanitize_relpath(p: str) -> str:
    p = p.replace("..", "__")
    p = re.sub(r'[<>:"|?*]', "_", p)
    return p


def sse_event(event: str, data: Dict) -> str:
    return f"event: {event}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"


def safe_err(msg: str) -> str:
    if not msg:
        return "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"
    msg = re.sub(r"(app-[A-Za-z0-9_\-]{10,})", "app-***REDACTED***", msg)
    msg = re.sub(r"(Bearer\s+)[A-Za-z0-9_\-\.=]+", r"\1***REDACTED***", msg, flags=re.IGNORECASE)
    msg = re.sub(r"https?://[^\s]+", "[URL_REDACTED]", msg)
    return msg[:300]


def convert_via_dify_chat_messages_secure(
    api_base: str,
    api_key: str,
    user: str,
    source_path: str,
    source_meta: Dict[str, str],
    text: str,
    knowledge_style: str,
    chunk_sep: str,
) -> str:
    url = f"{api_base}/chat-messages"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    instruction = build_rag_instruction(
        source_path=source_path,
        source_meta=source_meta,
        knowledge_style=knowledge_style,
        chunk_sep=chunk_sep,
    )

    query = (
        instruction
        + "\n\n===== SOURCE TEXT BEGIN =====\n"
        + text
        + "\n===== SOURCE TEXT END =====\n"
    )

    payload = {
        "inputs": {},
        "query": query,
        "response_mode": "blocking",
        "user": user,
    }

    try:
        r = requests.post(url, headers=headers, json=payload, timeout=REQ_TIMEOUT_SEC)
    except requests.RequestException:
        raise RuntimeError("APIé€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯/ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰ã€‚")

    if r.status_code >= 400:
        raise RuntimeError(f"APIã‚¨ãƒ©ãƒ¼ï¼ˆHTTP {r.status_code}ï¼‰ã€‚")

    try:
        data = r.json()
    except Exception:
        raise RuntimeError("APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    answer = data.get("answer")
    if not answer or not isinstance(answer, str):
        raise RuntimeError("APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæƒ³å®šå¤–ã§ã™ï¼ˆanswerãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")

    return answer.strip() + "\n"


def build_rag_instruction(source_path: str, source_meta: Dict[str, str], knowledge_style: str, chunk_sep: str) -> str:
    meta_lines = "\n".join([f"- {k}: {v}" for k, v in source_meta.items()])
    ext = (source_meta.get("ext") or "").lower()

    first_chunk_rule = f"""
        # æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ï¼ˆå¿…é ˆï¼‰
        - å‡ºåŠ›ã®æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã¯å¿…ãšã€Œå…¨ä½“æ§‹æˆï¼ˆç›®æ¬¡/åˆ†é¡ï¼‰ã€ã«ã™ã‚‹ã€‚
        - å½¢å¼ä¾‹ï¼š
        - è¦‹å‡ºã—: ã€Œ## å…¨ä½“æ§‹æˆï¼ˆç›®æ¬¡/åˆ†é¡ï¼‰ã€
        - æ¬¡ã®1æ–‡: ã€Œã“ã®ãƒãƒ£ãƒ³ã‚¯ã§ã¯æ–‡æ›¸å…¨ä½“ã®æ§‹æˆï¼ˆç›®æ¬¡ï¼‰ã¨åˆ†é¡æ–¹é‡ã‚’ç¤ºã™ã€‚ã€
        - ç¶šã‘ã¦ã€ç« ç«‹ã¦ï¼ˆå¤§ã‚«ãƒ†ã‚´ãƒªï¼‰ã¨ã€ãã®ä¸­ã§æ‰±ã†å†…å®¹ã®è¦ç´„ã‚’ç®‡æ¡æ›¸ãã§æ›¸ãã€‚
        - ãã®ãƒãƒ£ãƒ³ã‚¯ã®æœ«å°¾ã«å¿…ãšã€Œ{chunk_sep}ã€ã‚’å˜ç‹¬è¡Œã§ç½®ãã€‚
        """

    excel_rules = ""
    if ext in {".xlsx", ".xls", ".xlsm"} and knowledge_style != "rag_natural":
        excel_rules = f"""
        # Excelç‰¹åˆ¥ãƒ«ãƒ¼ãƒ«ï¼ˆæ¨™æº–/FAQç”¨ï¼‰
        - å…¥åŠ›ã«ã¯ [HEADER] ã¨ [ROW] ãŒå«ã¾ã‚Œã‚‹ã€‚
        - å‡ºåŠ›ã¯ã€Œãƒ‡ãƒ¼ã‚¿è¡Œï¼ˆ[ROW]ï¼‰1ã¤ã«ã¤ãã€å¿…ãšãƒãƒ£ãƒ³ã‚¯1ã¤ã€ã«ã™ã‚‹ã€‚
        - ãƒãƒ£ãƒ³ã‚¯åŒºåˆ‡ã‚Šã¯å¿…ãšã€Œ{chunk_sep}ã€ã®å˜ç‹¬è¡Œã«ã™ã‚‹ã€‚
        - [ROW]ã‚’çµ±åˆã—ãªã„ã€‚è¡ŒåŒå£«ã‚’ã¾ã¨ã‚ãªã„ã€‚
        """

    if knowledge_style == "rag_natural":
        style_block = f"""
        å‡ºåŠ›ã¯Markdownã§ã€ŒRAGå‘ã‘Markdownï¼ˆè‡ªç„¶è¨€èªï¼‰ã€ã¨ã—ã¦æ•´å½¢ã™ã‚‹ã€‚

        # æ‰‹é †ï¼ˆå¿…é ˆï¼‰
        1) ã¾ãšæ–‡æ›¸å…¨ä½“ã®æ§‹æˆã‚’æŠŠæ¡ã—ã€ä¸Šä½ã®ç« ç«‹ã¦ï¼ˆå¤§ã‚«ãƒ†ã‚´ãƒªï¼‰ã‚’ä½œã‚‹ã€‚
        2) æ¬¡ã«ã€äººé–“ãŒæŒ‡ç¤ºã‚’å‡ºã™ã‚ˆã†ãªè‡ªç„¶æ–‡ã§å„ãƒãƒ£ãƒ³ã‚¯ã®ç›®çš„ã‚’å®£è¨€ã—ã¦ã‹ã‚‰æœ¬æ–‡ã‚’ç½®ãã€‚
        3) ãƒãƒ£ãƒ³ã‚¯åŒºåˆ‡ã‚Šã¯å¿…ãšã€Œ{chunk_sep}ã€ã®å˜ç‹¬è¡Œã«ã™ã‚‹ã€‚

        # ãƒãƒ£ãƒ³ã‚¯ã®æ›¸ãæ–¹ï¼ˆå¿…é ˆï¼‰
        - å„ãƒãƒ£ãƒ³ã‚¯ã¯æ¬¡ã®é †åºã§æ›¸ãï¼š
        - è¦‹å‡ºã—ï¼ˆä¾‹ï¼š## â—‹â—‹ï¼‰
        - ã€Œã“ã®ãƒãƒ£ãƒ³ã‚¯ã§ã¯ã€œã‚’èª¬æ˜ã™ã‚‹ã€‚ã€ã®ã‚ˆã†ãªè‡ªç„¶è¨€èªã®å°å…¥æ–‡
        - æœ¬æ–‡ï¼ˆè¦ç‚¹â†’è©³ç´°â†’æ‰‹é †â†’ä¾‹â†’æ³¨æ„ï¼‰
        - è¦‹å‡ºã—ã¯æ¤œç´¢ã•ã‚Œã‚„ã™ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹ï¼ˆå›ºæœ‰åè©/æ‰‹é †å/æ¡ä»¶/ä¾‹å¤–/é–¾å€¤ï¼‰ã€‚

        # åˆ†å‰²æ–¹é‡ï¼ˆå¿…é ˆï¼‰
        - ã€Œç« /ç¯€/è©±é¡Œ/æ‰‹é †ã®ã¾ã¨ã¾ã‚Šã€ã§åŒºåˆ‡ã‚‹ã€‚
        - é•·ã„å ´åˆã¯ã€æ‰‹é †ã‚„è¦³ç‚¹ã§è¿½åŠ åˆ†å‰²ã—ã¦ã‚ˆã„ã€‚
        - ãŸã ã—æƒ…å ±ã¯çœç•¥ã—ãªã„ï¼ˆé‡è¤‡ã¯çµ±åˆå¯ï¼‰ã€‚
        """
    elif knowledge_style == "faq":
        style_block = f"""
        å‡ºåŠ›ã¯Markdownã§ã€FAQå½¢å¼ã«ã™ã‚‹ã€‚
        - è³ªå•ã¯å…·ä½“çš„ã«ã€å›ç­”ã¯çŸ­ãã€Œçµè«–â†’æ ¹æ‹ â†’ä¾‹ã€ã®é †ã«ã™ã‚‹ã€‚
        - ãƒãƒ£ãƒ³ã‚¯åŒºåˆ‡ã‚Šã¯å¿…ãšã€Œ{chunk_sep}ã€ã®å˜ç‹¬è¡Œã«ã™ã‚‹ã€‚
        """
    else:
        style_block = f"""
        å‡ºåŠ›ã¯Markdownã§ã€RAGã«æœ€é©åŒ–ã—ãŸãƒŠãƒ¬ãƒƒã‚¸ã¸æ•´å½¢ã™ã‚‹ã€‚
        - æ–‡ã¯ã€Œä¸»èª + è¿°èªã€ã§ã§ãã‚‹ã ã‘æ˜ç¢ºã«ã™ã‚‹ã€‚
        - æ¤œç´¢ã•ã‚Œã‚„ã™ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå›ºæœ‰åè©/æ‰‹é †å/æ¡ä»¶/ä¾‹å¤–/é–¾å€¤ï¼‰ã‚’å«ã‚ã‚‹ã€‚
        - ãƒãƒ£ãƒ³ã‚¯åŒºåˆ‡ã‚Šã¯å¿…ãšã€Œ{chunk_sep}ã€ã®å˜ç‹¬è¡Œã«ã™ã‚‹ã€‚
        - æƒ…å ±ã‚’çœç•¥ã—ãªã„ï¼ˆé‡è¤‡ã¯çµ±åˆå¯ï¼‰ã€‚
        """

    return f"""
        ã‚ãªãŸã¯ã€Œç¤¾å†…RAGç”¨ãƒŠãƒ¬ãƒƒã‚¸æ•´å½¢AIã€ã§ã‚ã‚‹ã€‚
        å…¥åŠ›ã•ã‚ŒãŸæ–‡ç« ã‚’ã€æ¤œç´¢ç²¾åº¦ãŒæœ€å¤§åŒ–ã™ã‚‹Markdownã¸å†æ§‹æˆã™ã‚‹ã€‚

        # å¤‰æ›å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
        - path: {source_path}
        - meta:
        {meta_lines}

        # çµ¶å¯¾ãƒ«ãƒ¼ãƒ«
        - å‡ºåŠ›ã¯ã€Œå¤‰æ›å¾ŒMarkdownæœ¬æ–‡ã®ã¿ã€ã¨ã™ã‚‹ï¼ˆå‰ç½®ã/è§£èª¬/è¬ç½ª/æ³¨é‡ˆã¯ç¦æ­¢ï¼‰ã€‚
        - åŸæ–‡ãŒæ›–æ˜§ãªå ´åˆã¯ã€Œã€œã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€ç­‰ã§è£œã„ã€æé€ ã—ãªã„ã€‚
        - ãƒãƒ£ãƒ³ã‚¯åŒºåˆ‡ã‚Šã¯å¿…ãšã€Œ{chunk_sep}ã€ã®å˜ç‹¬è¡Œã«ã™ã‚‹ã€‚

        {first_chunk_rule}

        {excel_rules}

        # ã‚¹ã‚¿ã‚¤ãƒ«
        {style_block}
        """.strip()


if __name__ == "__main__":
    app = create_app()
    app.run(host="0.0.0.0", port=5210, debug=False, threaded=True)